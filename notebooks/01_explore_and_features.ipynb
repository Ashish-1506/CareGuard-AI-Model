{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CareGuard AI - Model Exploration Notebook\n",
    "\n",
    "This notebook demonstrates the CareGuard AI chronic care risk prediction model.\n",
    "\n",
    "## Overview\n",
    "- Load and explore synthetic patient data\n",
    "- Train the risk prediction model\n", 
    "- Generate explanations using SHAP\n",
    "- Evaluate model performance\n",
    "- Test individual patient predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Import custom modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from synth_data import generate_synthetic_data\n",
    "from features import FeatureEngineer\n",
    "from train import ChronicRiskPredictor\n",
    "from explain import ModelExplainer\n",
    "from utils import create_synthetic_patient\n",
    "\n",
    "print(\"CareGuard AI Model Exploration\")\n",
    "print(\"==============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate synthetic patient data\n",
    "print(\"Generating synthetic chronic care patient data...\")\n",
    "df = generate_synthetic_data()\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Deterioration rate: {df['label_90d'].mean():.2%}\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Explore data distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Age distribution by outcome\n",
    "axes[0, 0].hist([df[df['label_90d']==0]['age'], df[df['label_90d']==1]['age']], \n",
    "               bins=20, alpha=0.7, label=['No Deterioration', 'Deterioration'])\n",
    "axes[0, 0].set_xlabel('Age')\n",
    "axes[0, 0].set_title('Age Distribution by Outcome')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# HbA1c distribution\n",
    "axes[0, 1].hist([df[df['label_90d']==0]['hba1c_last'], df[df['label_90d']==1]['hba1c_last']], \n",
    "               bins=20, alpha=0.7, label=['No Deterioration', 'Deterioration'])\n",
    "axes[0, 1].set_xlabel('HbA1c (%)')\n",
    "axes[0, 1].set_title('HbA1c Distribution by Outcome')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Adherence distribution\n",
    "axes[0, 2].hist([df[df['label_90d']==0]['adherence_mean'], df[df['label_90d']==1]['adherence_mean']], \n",
    "               bins=20, alpha=0.7, label=['No Deterioration', 'Deterioration'])\n",
    "axes[0, 2].set_xlabel('Medication Adherence')\n",
    "axes[0, 2].set_title('Adherence Distribution by Outcome')\n",
    "axes[0, 2].legend()\n",
    "\n",
    "# Condition distribution\n",
    "condition_counts = df['condition_primary'].value_counts()\n",
    "axes[1, 0].bar(condition_counts.index, condition_counts.values)\n",
    "axes[1, 0].set_xlabel('Primary Condition')\n",
    "axes[1, 0].set_title('Primary Condition Distribution')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Deterioration by condition\n",
    "deterioration_by_condition = df.groupby('condition_primary')['label_90d'].mean()\n",
    "axes[1, 1].bar(deterioration_by_condition.index, deterioration_by_condition.values)\n",
    "axes[1, 1].set_xlabel('Primary Condition')\n",
    "axes[1, 1].set_ylabel('Deterioration Rate')\n",
    "axes[1, 1].set_title('Deterioration Rate by Condition')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Correlation heatmap\n",
    "numeric_cols = ['age', 'hba1c_last', 'weight_trend_30d', 'adherence_mean', \n",
    "               'bnp_last', 'egfr_trend_90d', 'label_90d']\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[1, 2])\n",
    "axes[1, 2].set_title('Feature Correlation Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize feature engineer\n",
    "fe = FeatureEngineer()\n",
    "\n",
    "# Create engineered features\n",
    "print(\"Engineering features...\")\n",
    "df_features = fe.create_features(df)\n",
    "X = fe.prepare_model_features(df_features)\n",
    "\n",
    "print(f\"Original features: {len(df.columns)}\")\n",
    "print(f\"Engineered features: {len(df_features.columns)}\")\n",
    "print(f\"Model features: {len(X.columns)}\")\n",
    "\n",
    "# Display feature descriptions\n",
    "descriptions = fe.get_feature_descriptions()\n",
    "print(\"\\nFeature Descriptions:\")\n",
    "for feature, desc in list(descriptions.items())[:10]:\n",
    "    print(f\"  {feature}: {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize predictor\n",
    "predictor = ChronicRiskPredictor()\n",
    "\n",
    "# Prepare target\n",
    "y = df['label_90d'].values\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = predictor.split_data(X, y)\n",
    "\n",
    "print(f\"Training set: {len(X_train)} patients\")\n",
    "print(f\"Test set: {len(X_test)} patients\")\n",
    "print(f\"Training positive rate: {y_train.mean():.3f}\")\n",
    "print(f\"Test positive rate: {y_test.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Scale features\n",
    "X_train_scaled = predictor.scaler.fit_transform(X_train)\n",
    "X_test_scaled = predictor.scaler.transform(X_test)\n",
    "\n",
    "# Train models\n",
    "print(\"Training baseline model...\")\n",
    "predictor.train_baseline_model(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Training XGBoost model...\")\n",
    "predictor.train_primary_model(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Calibrating model...\")\n",
    "predictor.calibrate_model(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate models\n",
    "results = predictor.evaluate_models(X_test_scaled, y_test)\n",
    "\n",
    "# Display results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name.upper()} MODEL PERFORMANCE:\")\n",
    "    for metric, value in metrics.items():\n",
    "        if metric not in ['Confusion_Matrix']:\n",
    "            print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Feature importance\n",
    "importance_df = predictor.get_feature_importance()\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(importance_df['feature'][:15], importance_df['importance'][:15])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 15 Feature Importances (XGBoost)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "for i, row in importance_df.head(10).iterrows():\n",
    "    print(f\"{i+1:2d}. {row['feature']:<25} {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save model first\n",
    "predictor.save_model('../models/model.pkl')\n",
    "\n",
    "# Initialize explainer\n",
    "explainer = ModelExplainer('../models/model.pkl')\n",
    "\n",
    "# Prepare data for explanation\n",
    "X_scaled_exp, X_raw_exp, df_features_exp = explainer.prepare_data(df.head(100))\n",
    "\n",
    "print(\"Generating SHAP explanations...\")\n",
    "shap_values, sample_indices = explainer.explain_cohort(X_scaled_exp, max_samples=50)\n",
    "\n",
    "print(\"SHAP analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot global SHAP summary\n",
    "explainer.plot_global_summary()\n",
    "explainer.plot_feature_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Individual Patient Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create test patients with different risk levels\n",
    "print(\"Creating test patients...\\n\")\n",
    "\n",
    "# High-risk patient\n",
    "high_risk_patient = create_synthetic_patient(risk_level='high')\n",
    "print(\"HIGH-RISK PATIENT:\")\n",
    "print(high_risk_patient[['age', 'condition_primary', 'hba1c_last', 'adherence_mean', 'bnp_last']].iloc[0])\n",
    "\n",
    "# Get prediction and explanation\n",
    "explanation = explainer.explain_patient(high_risk_patient, 'HIGH_RISK_001')\n",
    "\n",
    "print(f\"\\nRisk Probability: {explanation['risk_probability']:.1%}\")\n",
    "print(f\"Risk Band: {explanation['risk_band']}\")\n",
    "print(f\"\\nClinical Summary: {explanation['clinical_summary']}\")\n",
    "print(\"\\nTop Risk Drivers:\")\n",
    "for driver in explanation['top_drivers'][:3]:\n",
    "    print(f\"  ‚Ä¢ {driver['description']}: {driver['impact']} risk (SHAP: {driver['shap_value']:.3f})\")\n",
    "print(\"\\nRecommendations:\")\n",
    "for rec in explanation['recommendations'][:2]:\n",
    "    print(f\"  ‚Ä¢ {rec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Low-risk patient\n",
    "low_risk_patient = create_synthetic_patient(risk_level='low')\n",
    "print(\"\\nLOW-RISK PATIENT:\")\n",
    "print(low_risk_patient[['age', 'condition_primary', 'hba1c_last', 'adherence_mean', 'bnp_last']].iloc[0])\n",
    "\n",
    "# Get prediction and explanation\n",
    "explanation = explainer.explain_patient(low_risk_patient, 'LOW_RISK_001')\n",
    "\n",
    "print(f\"\\nRisk Probability: {explanation['risk_probability']:.1%}\")\n",
    "print(f\"Risk Band: {explanation['risk_band']}\")\n",
    "print(f\"\\nClinical Summary: {explanation['clinical_summary']}\")\n",
    "print(\"\\nTop Risk Drivers:\")\n",
    "for driver in explanation['top_drivers'][:3]:\n",
    "    print(f\"  ‚Ä¢ {driver['description']}: {driver['impact']} risk (SHAP: {driver['shap_value']:.3f})\")\n",
    "print(\"\\nRecommendations:\")\n",
    "for rec in explanation['recommendations'][:2]:\n",
    "    print(f\"  ‚Ä¢ {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Risk Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate predictions for entire cohort\n",
    "X_cohort_scaled = predictor.scaler.transform(X)\n",
    "cohort_probs = predictor.calibrated_model.predict_proba(X_cohort_scaled)[:, 1]\n",
    "\n",
    "# Create risk bands\n",
    "risk_bands = pd.cut(cohort_probs, bins=[-0.01, 0.1, 0.25, 1.0], labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# Analysis by risk band\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Risk probability distribution\n",
    "axes[0, 0].hist(cohort_probs, bins=40, alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].axvline(predictor.threshold, color='red', linestyle='--', label=f'Threshold ({predictor.threshold:.2f})')\n",
    "axes[0, 0].set_xlabel('Risk Probability')\n",
    "axes[0, 0].set_ylabel('Number of Patients')\n",
    "axes[0, 0].set_title('Risk Probability Distribution')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Risk bands\n",
    "band_counts = risk_bands.value_counts()\n",
    "axes[0, 1].pie(band_counts.values, labels=band_counts.index, autopct='%1.1f%%', \n",
    "              colors=['#4caf50', '#ff9800', '#f44336'])\n",
    "axes[0, 1].set_title('Risk Band Distribution')\n",
    "\n",
    "# Deterioration rate by risk band\n",
    "deterioration_by_band = df.groupby(risk_bands)['label_90d'].agg(['mean', 'count']).reset_index()\n",
    "axes[1, 0].bar(deterioration_by_band.index, deterioration_by_band['mean'], \n",
    "              color=['#4caf50', '#ff9800', '#f44336'])\n",
    "axes[1, 0].set_xlabel('Risk Band')\n",
    "axes[1, 0].set_ylabel('Actual Deterioration Rate')\n",
    "axes[1, 0].set_title('Actual Deterioration Rate by Risk Band')\n",
    "axes[1, 0].set_xticks(range(3))\n",
    "axes[1, 0].set_xticklabels(['Low', 'Medium', 'High'])\n",
    "\n",
    "# Risk by age groups\n",
    "age_groups = pd.cut(df['age'], bins=[0, 50, 65, 75, 100], labels=['<50', '50-64', '65-74', '75+'])\n",
    "risk_by_age = pd.DataFrame({'age_group': age_groups, 'risk_prob': cohort_probs})\n",
    "risk_by_age.boxplot(column='risk_prob', by='age_group', ax=axes[1, 1])\n",
    "axes[1, 1].set_xlabel('Age Group')\n",
    "axes[1, 1].set_ylabel('Risk Probability')\n",
    "axes[1, 1].set_title('Risk Distribution by Age Group')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"RISK BAND ANALYSIS:\")\n",
    "for band in ['Low', 'Medium', 'High']:\n",
    "    mask = (risk_bands == band)\n",
    "    count = mask.sum()\n",
    "    pct = count / len(risk_bands) * 100\n",
    "    actual_rate = df[mask]['label_90d'].mean() if count > 0 else 0\n",
    "    avg_prob = cohort_probs[mask].mean() if count > 0 else 0\n",
    "    print(f\"{band} Risk: {count} patients ({pct:.1f}%) - Avg prob: {avg_prob:.1%}, Actual rate: {actual_rate:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Clinical Decision Support Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Simulate clinical decision support workflow\n",
    "print(\"CLINICAL DECISION SUPPORT SIMULATION\")\n",
    "print(\"===================================\\n\")\n",
    "\n",
    "# Identify high-risk patients\n",
    "high_risk_mask = (cohort_probs >= predictor.threshold)\n",
    "high_risk_patients = df[high_risk_mask].copy()\n",
    "high_risk_patients['risk_probability'] = cohort_probs[high_risk_mask]\n",
    "\n",
    "print(f\"Total patients in cohort: {len(df)}\")\n",
    "print(f\"Patients flagged as high-risk: {len(high_risk_patients)} ({len(high_risk_patients)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Sort by risk score\n",
    "high_risk_patients = high_risk_patients.sort_values('risk_probability', ascending=False)\n",
    "\n",
    "print(f\"\\nTOP 10 HIGHEST RISK PATIENTS:\")\n",
    "print(\"=" * 80)\n",
    "\n",
    "display_cols = ['patient_id', 'patient_name', 'age', 'condition_primary', \n",
    "               'hba1c_last', 'adherence_mean', 'risk_probability']\n",
    "\n",
    "for i, (_, patient) in enumerate(high_risk_patients.head(10).iterrows()):\n",
    "    print(f\"{i+1:2d}. Patient {patient['patient_id']} ({patient['patient_name']})\\
",
    "    Age: {patient['age']:.0f}, Condition: {patient['condition_primary']}\\
",
    "    Risk: {patient['risk_probability']:.1%}, HbA1c: {patient['hba1c_last']:.1f}%, Adherence: {patient['adherence_mean']:.0%}\")\n",
    "    \n",
    "    # Generate quick explanation\n",
    "    patient_df = df[df['patient_id'] == patient['patient_id']]\n",
    "    explanation = explainer.explain_patient(patient_df, patient['patient_id'])\n",
    "    print(f\"    Summary: {explanation['clinical_summary']}\")\n",
    "    print(f\"    Action: {explanation['recommendations'][0] if explanation['recommendations'] else 'Routine follow-up'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"CAREGUARD AI MODEL SUMMARY\")\n",
    "print(\"=========================\\n\")\n",
    "\n",
    "# Model performance summary\n",
    "final_metrics = results['calibrated']\n",
    "print(\"MODEL PERFORMANCE:\")\n",
    "print(f\"  AUROC: {final_metrics['AUROC']:.3f}\")\n",
    "print(f\"  AUPRC: {final_metrics['AUPRC']:.3f}\")\n",
    "print(f\"  Sensitivity: {final_metrics['Sensitivity']:.3f}\")\n",
    "print(f\"  Specificity: {final_metrics['Specificity']:.3f}\")\n",
    "print(f\"  Precision: {final_metrics['Precision']:.3f}\")\n",
    "\n",
    "# Clinical utility\n",
    "tp = final_metrics['Confusion_Matrix'][1][1]\n",
    "fp = final_metrics['Confusion_Matrix'][0][1]\n",
    "total_flagged = tp + fp\n",
    "nns = total_flagged / tp if tp > 0 else float('inf')\n",
    "\n",
    "print(\"\\nCLINICAL UTILITY:\")\n",
    "print(f\"  Patients flagged: {total_flagged} ({total_flagged/len(y_test)*100:.1f}% of cohort)\")\n",
    "print(f\"  True positives found: {tp}\")\n",
    "print(f\"  Number needed to screen: {nns:.1f}\")\n",
    "\n",
    "# Risk stratification\n",
    "print(\"\\nRISK STRATIFICATION:\")\n",
    "for band in ['Low', 'Medium', 'High']:\n",
    "    mask = (risk_bands == band)\n",
    "    count = mask.sum()\n",
    "    pct = count / len(risk_bands) * 100\n",
    "    print(f\"  {band} Risk: {count} patients ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\nNEXT STEPS:\")\n",
    "print(\"  1. Launch Streamlit dashboard: streamlit run ../app/streamlit_app.py\")\n",
    "print(\"  2. Start FastAPI server: uvicorn ../src/api:app --reload\")\n",
    "print(\"  3. Integrate with EHR system for real-time predictions\")\n",
    "print(\"  4. Conduct prospective validation study\")\n",
    "print(\"  5. Deploy to production with monitoring\")\n",
    "\n",
    "print(\"\\nüè• CareGuard AI is ready for clinical decision support! üöÄ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}